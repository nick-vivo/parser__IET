Искусственный интеллект — наука и технология создания интеллектуальных машин, особенно интеллектуальных компьютерных программ.
Верно

Кибернетика — наука об общих закономерностях получения, хранения, преобразования и передачи информации в сложных управляющих системах.
Верно

Наивный байесовский классификатор — простой вероятностный классификатор, основанный на применении Теоремы Байеса со строгими (наивными) предположениями о зависимости.
Верно

Наивный байесовский классификатор - классификатор, для которого общий риск не зависит от априорной вероятности.
Неверно

Совместными называются  события, которые не могут одновременно произойти в одном испытании.
Неверно

Задачей метода главных компонент является поиск линейной комбинации признаков, которые позволили бы наилучшим образом разделить рассматриваемые группы
Неверно

Основной идеей линейного дискриминанта Фишера является нахождение серединного перпендикуляра между центрами кластеров.
Неверно

Линейный дискриминант Фишера основан на вычислении ковариации между классами и ковариации внутри классов
Верно

Математическая модель нейрона МакКаллока-Питтса может аппроксимировать любую непрерывную функцию многих переменных с любой точностью.
Неверно

Алгоритм кластеризации k-means основан на методике итеративного вычисления оценок максимального правдоподобия.
Неверно

Алгоритм Хебба является методом обучения многослойных нейронных сетей прямого распространения.
Неверно

Однослойный персептрон представляет собой однослойную структуру с жесткой пороговой функцией процессорного элемента и бинарными или многозначными входами.
Неверно

Классификация образа X состоит в определении класса, которому принадлежит X.
Неверно

Недообучение возникает при решении задач обучения по прецедентам, когда алгоритм обучения не обеспечивает достаточно малой величины средней ошибки на обучающей выборке.
Верно

Эмпирический риск — задаёт среднюю величину потерь, связанных с принятием классификатором решения об отнесении данного вектора признаков  к заданному классу.
Неверно

Наивный байесовский классификатор определяет наиболее вероятную классификацию на заданном наборе данных.
Неверно

Задачей метода главных компонент является определение признаков, которые позволяют отнести наблюдение к той или иной группе.
Неверно

Цель дискриминантного анализа - преобразование взаимодействия многих признаков во взаимодействие небольшого числа признаков.
Верно

Целью обучения многослойного персептрона является минимизация общего риска.
Неверно

Задача обучения по прецедентам заключается в том, чтобы по заданной выборке построить решающую функцию, которая бы приближала целевую функцию, причём не только на объектах обучающей выборки, но и на всем множестве
Верно

Образ - совокупность признаков, характеризующих объект.
Верно

Задача кластеризации является обобщением задачи классификации.
Неверно

Задача классификации является обобщением задачи кластеризации.
Неверно

Ошибка второго рода равна вероятности принять основной класс за вторичный.
Неверно

Метод наименьших квадратов – это статистическая процедура, позволяющая решить задачу оптимального уменьшения объёма исходных многомерных данных путём перехода к новым переменным.
Неверно

Линейный дискриминант Фишера определяет серединный перпендикуляр между центрами кластеров.
Неверно

Метод опорных векторов определяет гиперплоскость максимально отдалённую от выпуклой оболочки классов
Верно

Кибернетический нейрон выполняет нелинейное преобразование и передачу результирующего значения связанным с ним нейронам.
Верно

Цель кластеризации – построить оптимальное разбиение объектов на группы.
Верно

Распознавание образов — разбиение пространства на области категорий и классов
Верно

Задача машинного обучения сводится к решению задачи минимизации общего риска.
Неверно

ROC-кривая показывает зависимость количества верно классифицированных положительных примеров от количества неверно классифицированных отрицательных примеров.
Верно

Равновозможными называются события, если ни у одного из них нет объективного преимущества перед другим.
Неверно

Идея алгоритма Гиббса заключается в выборе случайной гипотезы согласно распределению их условных вероятностей
Неверно

Цель факторного анализа - преобразование взаимодействия многих признаков во взаимодействие небольшого числа признаков.
Верно

Основной идеей линейного дискриминанта Фишера является минимизация перекрытия классов путем оптимизации расстояния между классами и дисперсии каждого кластера.
Верно

Целью обучения многослойного персептрона является минимизация эмпирического риска.
Неверно

Задача кластеризации – построить оптимальное разбиение объектов на группы.
Неверно

Математическая модель элементарного персептрона позволяет реализовать различные логические функции.
Неверно

Кибернетика — наука об общих закономерностях получения, хранения, преобразования и передачи информации в живых системах.
Неверно

Отнесение образца к некоторому классу называется задачей описания.
Неверно

Машинное обучение не применяется для оценивания функций плотности распределения в многомерном пространстве.
Неверно

Задача применения наивного байесовского классификатора - выбор гипотезы с минимальной апостериорной вероятностью.
Неверно

В алгоритме баггинга базовые алгоритмы обучаются и работают независимо друг от друга.
Верно

Задача машинного обучения сводится к решению задачи максимизации общего риска.
Неверно

Метод состоятелен, если он с большой вероятностью делает маленькую ошибку на данных не присутствовавших в обучающей выборке.
Верно

В алгоритме бустинга базовые алгоритмы строятся последовательно, последовательно уточняя ошибки классификации.
Верно

Метод наименьших квадратов определяет гиперплоскость максимально отдалённую от выпуклой оболочки классов
Неверно

Задачей метода наименьших квадратов является поиск линейной комбинации признаков, которые позволили бы наилучшим образом разделить рассматриваемые группы
Неверно

Метод главных компонент основан на вычислении ковариации между классами и ковариации внутри классов
Неверно

Метод главных компонент определяет гиперплоскость максимально отдалённую от выпуклой оболочки классов
Неверно

Элементарный персептрон может аппроксимировать любую непрерывную функцию многих переменных с любой точностью.
Неверно

Алгоритм Хебба предназначен для обучения обучения многослойных нейронных сетей прямого распространения.
Неверно

Математическая модель нейрона МакКаллока-Питтса позволяет реализовать различные логические функции.
Верно

Машинное обучение применяется для обнаружения в данных ранее неизвестных, практически полезных и доступных интерпретации знаний.
Неверно

Машинное обучение не применяется для обнаружения в данных ранее неизвестных, практически полезных и доступных интерпретации знаний.
Верно

Задачей метода метода опорных векторов является поиск линейной комбинации признаков, которые позволили бы наилучшим образом разделить рассматриваемые группы
Неверно

Алгоритм Хебба предназначен для обучения однослойного персептрона.
Неверно

Кибернетический нейрон имеет тело, совокупность отростков, по которым в нейрон поступают входные сигналы, и отросток, передающий выходной сигнал нейрона другим нейронам.
Верно

Переобучение возникает при решении задач обучения по прецедентам, когда алгоритм обучения не обеспечивает достаточно малой величины средней ошибки на обучающей выборке.
Неверно

Машинное обучение применяется при высокой размерности задачи.
Верно

Объединение объектов в осмысленные группы называется задачей классификации.
Неверно

Переобучение возникает при решении задач обучения по прецедентам, когда вероятность ошибки обученного алгоритма на объектах тестовой выборки оказывается существенно выше, чем средняя ошибка на обучающей выборке.
Верно

Для построения наивного байесовского классификатора нужно знать только априорные вероятности.
Неверно

Для построения наивного байесовского классификатора нужно знать функцию правдоподобия и априорные вероятности.
Верно

Вероятностью события А называют отношение числа благоприятствующих этому событию элементарных событий к общему числу всех равновозможных независимых элементарных событий, образующих полную группу
Верно

Задачей метода наименьших квадратов является определение признаков, которые позволяют отнести наблюдение к той или иной группе.
Неверно

Метод наименьших квадратов определяет оптимальную разделяющую гиперплоскость
Неверно

Дискриминантный анализ - раздел вычислительной математики, представляющий набор методов статистического анализа для решения задач распознавания образов, который используется для принятия решения о том, какие переменные разделяют (т.е. дискриминируют) возникающие наборы данных (так называемые группы).
Верно

Цель метода главных компонент - преобразование взаимодействия многих признаков во взаимодействие небольшого числа признаков.
Верно

Элементарный персептрон представляет собой однослойную структуру с жесткой пороговой функцией процессорного элемента и бинарными или многозначными входами
Верно

Алгоритм Хебба предназначен для обучения персептрона Розенблата.
Верно

Персептрон Розенблата может аппроксимировать любую непрерывную функцию многих переменных с любой точностью.
Неверно

EM алгоритм кластеризации основан на методике итеративного вычисления оценок максимального правдоподобия.
Верно

Искусственный интеллект — свойство интеллектуальных систем выполнять творческие функции.
Верно

Достоверными называются  события, которые не могут одновременно произойти в одном испытании.
Неверно

Невозможными называются  события, которые не могут одновременно произойти в одном испытании.
Неверно

Задачей метода опорных векторов является определение признаков, которые позволяют отнести наблюдение к той или иной группе.
Неверно

Цель кластеризации – разбиение заданной выборки объектов на непересекающиеся подмножества.
Неверно

